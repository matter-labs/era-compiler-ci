name: LNT benchmarks

on:
  workflow_call:
    inputs:
      compiler_tester_branch:
        type: string
        description: "compiler-tester branch to use as a benchmark candidate"
        required: false
        default: "main"
      compiler_llvm_branch:
        type: string
        description: "compiler-llvm branch to use as a benchmark candidate"
        required: false
        default: "main"
      ccache-key:
        type: string
        description: 'Github Actions cache key for CCache.'
        required: false
        default: ''
      compiler-tester-repo:
        type: string
        required: false
        default: 'matter-labs/era-compiler-tester'
        description: 'Compiler tester repository to use. Required for forks testing.'
      compiler-llvm-repo:
        type: string
        required: false
        default: 'matter-labs/era-compiler-llvm'
        description: 'Compiler LLVM repository to use. Required for forks testing.'
      use-dev-machine:
        type: boolean
        required: true
        default: false
        description: 'Use dev machine for PRs results.'

jobs:

  lnt-benchmarks:
    name: LNT benchmarks
    runs-on: matterlabs-ci-runner-high-performance
    container:
      image: ghcr.io/matter-labs/zksync-llvm-runner:latest
      options: -m 110g
    env:
      RESULTS_DIR: results
      LNT_SERVER_URL: http://llvm-lnt.infra.matterlabs.corp
      LNT_TEST_SUITE: zksync
      CONFIG_FILE: lntadmin.yaml
      DEV_PREFIX: DEV__
      LNT_RESULTS_FILE: lnt_results.txt
      CONTEXT_FILE: context.json
      COMPARISON_FILE: comparison_links.txt

    steps:

      - name: Checkout LNT
        uses: actions/checkout@v4
        with:
          repository: llvm/llvm-lnt
          path: lnt

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Install LNT
        run: cd lnt && pip install .

      - name: Define branches
        shell: bash -ex {0}
        id: define-branches
        run: |
          echo "compiler-tester-branch=${{ inputs.compiler_tester_branch || github.head_ref }}" | tee -a "${GITHUB_OUTPUT}"
          echo "llvm-branch=${{ inputs.compiler_llvm_branch || '' }}" | tee -a "${GITHUB_OUTPUT}"
          echo "compiler-tester-repo=${{ inputs.compiler-tester-repo || github.event.pull_request.head.repo.full_name }}" | tee -a "${GITHUB_OUTPUT}"

      - name: Checkout compiler-tester
        uses: actions/checkout@v4
        with:
          repository: ${{ steps.define-branches.outputs.compiler-tester-repo }}
          ref: ${{ steps.define-branches.outputs.compiler-tester-branch }}
          submodules: recursive

      - name: Checkout LLVM
        if: steps.define-branches.outputs.llvm-branch != ''
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.compiler-llvm-repo }}
          ref: ${{ steps.define-branches.outputs.llvm-branch }}
          path: llvm

      # An issue prevents to correctly use the same version of composite actions from `workflow_call`
      # https://github.com/actions/toolkit/issues/1264
      # for now, it will always be taken from the latest main
      - name: Build LLVM
        uses: matter-labs/era-compiler-ci/.github/actions/build-llvm@main
        with:
          build-type: Release
          clone-llvm: ${{ steps.define-branches.outputs.llvm-branch == '' && 'true' || 'false' }}
          enable-assertions: false
          ccache-key: ${{ inputs.ccache-key }}

      - name: Build compiler-tester
        run: cargo build --release --bin 'compiler-tester'

      - name: Build compilers
        env:
          CARGO_CHECKOUT_DIR: /usr/local/cargo/git/checkouts
        run: |
          cargo build --release \
            --manifest-path ${CARGO_CHECKOUT_DIR}/era-compiler-solidity-*/*/Cargo.toml \
            --target-dir './target-zksolc/'
          cargo build --release \
            --manifest-path ${CARGO_CHECKOUT_DIR}/era-compiler-vyper-*/*/Cargo.toml \
            --target-dir './target-zkvyper/'

      - name: Run benchmarks LNT
        shell: bash -ex {0}
        run: |
          ZKSOLC_OUTPUT=$(./target-zksolc/release/zksolc --version)
          ZKSOLC_VERSION=$(echo "${ZKSOLC_OUTPUT}" | grep -oP "v\d+\.\d+\.\d+")
          LLVM_VERSION=$(echo "${ZKSOLC_OUTPUT}" | grep -oP "(?<=LLVM build )[a-f0-9]{40}")

          if [[ "${{ inputs.use-dev-machine }}" == "true" ]]; then
            DEV_MACHINE_PREFIX="${DEV_PREFIX}"
          fi

          MODES=("Y+M3B3" "Y+MzB3" "E+M3B3 0.8" "E+MzB3 0.8")
          for MODE in "${MODES[@]}"; do
            for TOOLCHAIN in ir-llvm; do
              # Create a context file
              echo "{
                \"machine\": \"${DEV_MACHINE_PREFIX}llvm_eravm_${TOOLCHAIN}_${MODE// /_}\",
                \"target\": \"eravm\",
                \"toolchain\": \"${TOOLCHAIN}\",
                \"zksolc_version\": \"${ZKSOLC_VERSION}\",
                \"llvm_version\": \"${LLVM_VERSION}\"
              }" > "${CONTEXT_FILE}"
              # Run benchmarks
              ./target/release/compiler-tester \
                --zksolc ./target-zksolc/release/zksolc \
                --zkvyper ./target-zkvyper/release/zkvyper \
                --target eravm \
                --mode "${MODE}" \
                --toolchain "${TOOLCHAIN}" \
                --benchmark "${RESULTS_DIR}" \
                --benchmark-format json-lnt \
                --benchmark-context "${CONTEXT_FILE}" || true
            done
          done

          for TOOLCHAIN in solc ir-llvm; do
            if [[ "$TOOLCHAIN" == "solc" ]]; then
              MODES=("Y+")
            else
              MODES=("Y+M3B3" "Y+MzB3" "E+M3B3 0.8" "E+MzB3 0.8")
            fi
            for MODE in "${MODES[@]}"; do
              for ENV in REVM EVMInterpreter; do
                # Create a context file
                echo "{
                  \"machine\": \"${DEV_MACHINE_PREFIX}llvm_evm_${TOOLCHAIN}_${MODE// /_}_${ENV}\",
                  \"target\": \"evm\",
                  \"environment\": \"${ENV}\",
                  \"toolchain\": \"${TOOLCHAIN}\",
                  \"zksolc_version\": \"${ZKSOLC_VERSION}\",
                  \"llvm_version\": \"${LLVM_VERSION}\"
                }" > "${CONTEXT_FILE}"
                # Run benchmarks
                ./target/release/compiler-tester \
                  --zksolc ./target-zksolc/release/zksolc \
                  --zkvyper ./target-zkvyper/release/zkvyper \
                  --target evm \
                  --mode "${MODE}" \
                  --toolchain "${TOOLCHAIN}" \
                  --environment "${ENV}" \
                  --benchmark "${RESULTS_DIR}" \
                  --benchmark-format json-lnt \
                  --benchmark-context "${CONTEXT_FILE}" || true
              done
            done
          done
          find "${RESULTS_DIR}" -name '*.json'

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: 'results'
          path: 'results/*.json'

      - name: Submit LNT results
        shell: bash -ex {0}
        run: |
          for JSON in $(ls ${RESULTS_DIR}/*.json); do
            lnt submit --ignore-regressions --select-machine=update \
              ${LNT_SERVER_URL}/db_default/v4/${LNT_TEST_SUITE}/submitRun \
              "${JSON}" >> "${LNT_RESULTS_FILE}" 2>&1
          done

      - name: Prepare LNT admin
        if: ${{ github.event_name == 'pull_request' }}
        shell: bash -ex {0}
        run: |
          lnt admin create-config
          sed -i "s|lnt_url: \"http://localhost:8000\"|lnt_url: \"${LNT_SERVER_URL}\"|" "${CONFIG_FILE}"
          sed -i 's|testsuite: nts|testsuite: zksync|' "${CONFIG_FILE}"
          sed -i 's|# auth_token: .*|auth_token: '"'"'${{ secrets.LNT_ADMIN_TOKEN }}'"'"'|' "${CONFIG_FILE}"

      - name: Publish comparison links
        if: ${{ github.event_name == 'pull_request' }}
        shell: bash -ex {0}
        run: |
          run_orders=()
          while read -r line; do
            run_orders+=("$(echo "${line}" | awk -F'/' '{print $NF}')")
          done < "${LNT_RESULTS_FILE}"
          echo "Extracted run orders: ${run_orders[@]}"
          # Initialize the Markdown table
          echo '| Target | Mode    | Toolchain | Environment      | Link |' > "${COMPARISON_FILE}"
          echo '|--------|---------|-----------|------------------|------|' >> "${COMPARISON_FILE}"
          for RUN in "${run_orders[@]}"; do
            lnt admin get-run "${RUN}"
            RUN_MACHINE=$(jq -r '.machine.name' run_${RUN}.json)
            MAIN_MACHINE="${RUN_MACHINE//DEV__/}"
            LATEST_MAIN_RUN=$(lnt admin list-runs ${MAIN_MACHINE} | head -n 1 | cut -d ' ' -f2)
            if [[ -z "${LATEST_MAIN_RUN}" ]]; then
              echo "No main run found for ${MAIN_MACHINE}"
              continue
            fi
            # Extract metadata
            TARGET=$(echo "$MAIN_MACHINE" | grep -o 'eravm\|evm' || echo "")
            MODE=$(echo "$MAIN_MACHINE" | grep -o 'Y+M3B3\|Y+MzB3\|E+M3B3_0.8\|E+MzB3_0.8\|Y+' || echo "")
            TOOLCHAIN=$(echo "$MAIN_MACHINE" | grep -o 'solc\|ir-llvm' || echo "")
            ENVIRONMENT=$(echo "$MAIN_MACHINE" | grep -o 'EVMInterpreter\|REVM' || echo "")
            if [[ -z "$ENVIRONMENT" ]]; then
              ENVIRONMENT="zk_evm"
            fi
            RESULT_LINK="[Results](${LNT_SERVER_URL}/db_default/v4/${LNT_TEST_SUITE}/${RUN}?compare_to=${LATEST_MAIN_RUN})"
            echo "| ${TARGET} | ${MODE} | ${TOOLCHAIN} | ${ENVIRONMENT} | ${RESULT_LINK} |" >> "${COMPARISON_FILE}"
          done
          cat "${COMPARISON_FILE}"

      - name: Posting LNT comparison
        if: ${{ github.event_name == 'pull_request' }}
        uses: mshick/add-pr-comment@v2
        with:
          message-path: ${{ env.COMPARISON_FILE }}
          message-id: comparison_links
