name: LNT benchmarks

on:
  workflow_call:
    inputs:
      compiler_tester_branch:
        type: string
        description: "compiler-tester branch to use as a benchmark candidate"
        required: false
        default: "main"
      compiler_llvm_branch:
        type: string
        description: "compiler-llvm branch to use as a benchmark candidate"
        required: false
        default: "main"
      ccache-key:
        type: string
        description: 'Github Actions cache key for CCache.'
        required: false
        default: ''
      compiler-tester-repo:
        type: string
        required: false
        default: 'matter-labs/era-compiler-tester'
        description: 'Compiler tester repository to use. Required for forks testing.'
      compiler-llvm-repo:
        type: string
        required: false
        default: 'matter-labs/era-compiler-llvm'
        description: 'Compiler LLVM repository to use. Required for forks testing.'
      use-dev-machine:
        type: boolean
        required: true
        default: false
        description: 'Use dev machine for PRs results.'

jobs:

  lnt-benchmarks:
    name: LNT benchmarks
    runs-on: matterlabs-ci-runner-high-performance
    container:
      image: ghcr.io/matter-labs/zksync-llvm-runner:latest
      options: -m 110g
    env:
      RESULTS_DIR: results
      LNT_SERVER_URL: http://llvm-lnt.infra.matterlabs.corp
      LNT_TEST_SUITE: zksync
      CONFIG_FILE: lntadmin.yaml
      DEV_PREFIX: DEV__
      LNT_RESULTS_FILE: lnt_results.txt
      CONTEXT_FILE: context.json
      COMPARISON_FILE: comparison_links.txt

    steps:

      - name: Checkout LNT
        uses: actions/checkout@v4
        with:
          repository: llvm/llvm-lnt
          path: lnt

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Install LNT
        run: cd lnt && pip install .

      - name: Define branches
        shell: bash -ex {0}
        id: define-branches
        run: |
          echo "compiler-tester-branch=${{ inputs.compiler_tester_branch || github.head_ref }}" | tee -a "${GITHUB_OUTPUT}"
          echo "llvm-branch=${{ inputs.compiler_llvm_branch || '' }}" | tee -a "${GITHUB_OUTPUT}"
          echo "compiler-tester-repo=${{ inputs.compiler-tester-repo || github.event.pull_request.head.repo.full_name }}" | tee -a "${GITHUB_OUTPUT}"

      - name: Checkout compiler-tester
        uses: actions/checkout@v4
        with:
          repository: ${{ steps.define-branches.outputs.compiler-tester-repo }}
          ref: ${{ steps.define-branches.outputs.compiler-tester-branch }}
          submodules: recursive

      - name: Checkout LLVM
        if: steps.define-branches.outputs.llvm-branch != ''
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.compiler-llvm-repo }}
          ref: ${{ steps.define-branches.outputs.llvm-branch }}
          path: llvm

      - name: Building solc
        uses: matter-labs/era-compiler-ci/.github/actions/build-solc@main
        with:
          cmake-build-type: RelWithDebInfo
          working-dir: 'era-solidity'
          upload-testing-binary: false

      # An issue prevents to correctly use the same version of composite actions from `workflow_call`
      # https://github.com/actions/toolkit/issues/1264
      # for now, it will always be taken from the latest main
      - name: Build LLVM
        uses: matter-labs/era-compiler-ci/.github/actions/build-llvm@main
        with:
          build-type: Release
          clone-llvm: ${{ steps.define-branches.outputs.llvm-branch == '' && 'true' || 'false' }}
          enable-assertions: false
          ccache-key: ${{ inputs.ccache-key }}

      - name: Build compiler-tester
        run: cargo build --release --bin 'compiler-tester'

      - name: Build compilers
        env:
          CARGO_CHECKOUT_DIR: /usr/local/cargo/git/checkouts
          BOOST_PREFIX: ${{ github.workspace }}/era-solidity/boost/lib
          SOLC_PREFIX: ${{ github.workspace }}/era-solidity/build
        run: |
          cargo build --release \
            --manifest-path ${CARGO_CHECKOUT_DIR}/era-compiler-solidity-*/*/Cargo.toml \
            --target-dir './target-zksolc/'
          cargo build --release \
            --manifest-path ${CARGO_CHECKOUT_DIR}/era-compiler-vyper-*/*/Cargo.toml \
            --target-dir './target-zkvyper/'
          cargo build --release \
            --manifest-path ${CARGO_CHECKOUT_DIR}/solx-*/*/Cargo.toml \
            --target-dir './target-solx/'

      - name: Run benchmarks LNT
        shell: bash -ex {0}
        run: |
          if [[ "${{ inputs.use-dev-machine }}" == "true" ]]; then
            DEV_MACHINE_PREFIX="${DEV_PREFIX}"
          fi

          ZKSOLC_VERSION=$(./target-zksolc/release/zksolc --version)
          LLVM_VERSION=$(echo "${ZKSOLC_VERSION}" | grep -oP "(?<=LLVM build )[a-f0-9]{40}")
          SOLC_VERSIONS=("0.4" "0.5" "0.6" "0.7" "0.8")
          for SOLC in "${SOLC_VERSIONS[@]}"; do
            MODES=("E+M3B3 ${SOLC}" "E+MzB3 ${SOLC}")
            # if solc is 0.8, add E+M3B3 and E+MzB3
            if [[ "${SOLC}" == "0.8" ]]; then
              MODES+=("Y+M3B3 ${SOLC}" "Y+MzB3 ${SOLC}")
            fi
            for MODE in "${MODES[@]}"; do
              for TOOLCHAIN in ir-llvm; do
                # Create a context file
                echo "{
                  \"machine\": \"${DEV_MACHINE_PREFIX}llvm_eravm_${TOOLCHAIN}_${MODE// /_}\",
                  \"target\": \"eravm\",
                  \"toolchain\": \"${TOOLCHAIN}\",
                  \"compiler_version\": \"${ZKSOLC_VERSION}\",
                  \"llvm_version\": \"${LLVM_VERSION}\"
                }" > "${CONTEXT_FILE}"
                # Run benchmarks
                ./target/release/compiler-tester \
                  --zksolc ./target-zksolc/release/zksolc \
                  --zkvyper ./target-zkvyper/release/zkvyper \
                  --solx ./target-solx/release/solx \
                  --target eravm \
                  --mode "${MODE}" \
                  --toolchain "${TOOLCHAIN}" \
                  --benchmark "${RESULTS_DIR}" \
                  --benchmark-format json-lnt \
                  --benchmark-context "${CONTEXT_FILE}" || true
              done
            done
          done

          SOLX_VERSION=$(./target-solx/release/solx --version | head -n 1)
          SOLX_SOLC_VERSION=$(./target-solx/release/solx --version | tail -n 1)
          LLVM_VERSION=$(echo "${SOLX_VERSION}" | grep -oP "(?<=LLVM build: )[a-f0-9]{40}")
          for TOOLCHAIN in solc ir-llvm; do
            if [[ "$TOOLCHAIN" == "solc" ]]; then
              MODES=("Y+" "E+ 0.8")
            else
              MODES=("Y+M3B3" "Y+MzB3" "E+M3B3" "E+MzB3")
            fi
            for MODE in "${MODES[@]}"; do
              for ENV in EVMInterpreter; do
                # Create a context file
                echo "{
                  \"machine\": \"${DEV_MACHINE_PREFIX}llvm_evm_${TOOLCHAIN}_${MODE// /_}_${ENV}\",
                  \"target\": \"evm\",
                  \"environment\": \"${ENV}\",
                  \"toolchain\": \"${TOOLCHAIN}\",
                  \"compiler_version\": \"${SOLX_VERSION} ${SOLX_SOLC_VERSION}\",
                  \"llvm_version\": \"${LLVM_VERSION}\"
                }" > "${CONTEXT_FILE}"
                # Run benchmarks
                ./target/release/compiler-tester \
                  --zksolc ./target-zksolc/release/zksolc \
                  --zkvyper ./target-zkvyper/release/zkvyper \
                  --solx ./target-solx/release/solx \
                  --target evm \
                  --mode "${MODE}" \
                  --toolchain "${TOOLCHAIN}" \
                  --environment "${ENV}" \
                  --benchmark "${RESULTS_DIR}" \
                  --benchmark-format json-lnt \
                  --benchmark-context "${CONTEXT_FILE}" || true
              done
            done
          done
          find "${RESULTS_DIR}" -name '*.json'

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: 'results'
          path: 'results/*.json'

      - name: Submit LNT results
        shell: bash -ex {0}
        run: |
          for JSON in $(ls ${RESULTS_DIR}/*.json); do
            lnt submit --ignore-regressions --select-machine=update \
              ${LNT_SERVER_URL}/db_default/v4/${LNT_TEST_SUITE}/submitRun \
              "${JSON}" >> "${LNT_RESULTS_FILE}" 2>&1
          done

      - name: Prepare LNT admin
        if: ${{ github.event_name == 'pull_request' }}
        shell: bash -ex {0}
        run: |
          lnt admin create-config
          sed -i "s|lnt_url: \"http://localhost:8000\"|lnt_url: \"${LNT_SERVER_URL}\"|" "${CONFIG_FILE}"
          sed -i 's|testsuite: nts|testsuite: zksync|' "${CONFIG_FILE}"
          sed -i 's|# auth_token: .*|auth_token: '"'"'${{ secrets.LNT_ADMIN_TOKEN }}'"'"'|' "${CONFIG_FILE}"

      - name: Publish comparison links
        if: ${{ github.event_name == 'pull_request' }}
        shell: bash -ex {0}
        run: |
          run_orders=()
          while read -r line; do
            run_orders+=("$(echo "${line}" | awk -F'/' '{print $NF}')")
          done < "${LNT_RESULTS_FILE}"
          echo "Extracted run orders: ${run_orders[@]}"
          # Initialize the Markdown table
          echo '| Target | Mode    | Toolchain | Environment      | Link |' > "${COMPARISON_FILE}"
          echo '|--------|---------|-----------|------------------|------|' >> "${COMPARISON_FILE}"
          for RUN in "${run_orders[@]}"; do
            lnt admin get-run "${RUN}"
            RUN_MACHINE=$(jq -r '.machine.name' run_${RUN}.json)
            MAIN_MACHINE="${RUN_MACHINE//DEV__/}"
            LATEST_MAIN_RUN=$(lnt admin list-runs ${MAIN_MACHINE} | head -n 1 | cut -d ' ' -f2)
            if [[ -z "${LATEST_MAIN_RUN}" ]]; then
              echo "No main run found for ${MAIN_MACHINE}"
              continue
            fi
            # Extract metadata
            TARGET=$(echo "$MAIN_MACHINE" | grep -o 'eravm\|evm' || echo "")
            MODE=$(echo "$MAIN_MACHINE" | grep -o 'Y+M3B3\|Y+MzB3\|E+MzB3_0\.[0-9]\+\|E+M3B3_0\.[0-9]\+\|E+M3B3\|E+MzB3\|Y+\|E+_0.8' || echo "")
            TOOLCHAIN=$(echo "$MAIN_MACHINE" | grep -o 'solc\|ir-llvm' || echo "")
            ENVIRONMENT=$(echo "$MAIN_MACHINE" | grep -o 'EVMInterpreter' || echo "")
            if [[ -z "$ENVIRONMENT" ]]; then
              ENVIRONMENT="zk_evm"
            fi
            RESULT_LINK="[Results](${LNT_SERVER_URL}/db_default/v4/${LNT_TEST_SUITE}/${RUN}?compare_to=${LATEST_MAIN_RUN})"
            echo "| ${TARGET} | ${MODE} | ${TOOLCHAIN} | ${ENVIRONMENT} | ${RESULT_LINK} |" >> "${COMPARISON_FILE}"
          done
          cat "${COMPARISON_FILE}"

      - name: Posting LNT comparison
        if: ${{ github.event_name == 'pull_request' }}
        uses: mshick/add-pr-comment@v2
        with:
          message-path: ${{ env.COMPARISON_FILE }}
          message-id: comparison_links
